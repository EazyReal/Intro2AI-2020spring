{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Params and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./dat/iris.data\"\n",
    "TEST = True\n",
    "n_feature = 4\n",
    "n_class = 3\n",
    "LAB = 4\n",
    "# control default func in train or split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname, partition=(8,1,1)):\n",
    "    # read in, df to nparray\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    npd = np.array(df)\n",
    "    n = npd.shape[0]\n",
    "    \n",
    "    # tag to id, id to tag, transform\n",
    "    tag_map = defaultdict(int)\n",
    "    tag_to_id = defaultdict(int)\n",
    "    id_to_tag = defaultdict(int)\n",
    "    for d in npd:\n",
    "        tag_map[d[LAB]] += 1\n",
    "    \n",
    "    cnt = 0\n",
    "    for k, v in tag_map.items():\n",
    "        id_to_tag[cnt] = k\n",
    "        tag_to_id[k] = cnt\n",
    "        cnt += 1\n",
    "        \n",
    "    for i in range(n):\n",
    "        npd[i][LAB] = tag_to_id[npd[i][LAB]]\n",
    "    #print(tag_to_id)\n",
    "    #print(id_to_tag)\n",
    "    \n",
    "    # shuffle(no when testing)\n",
    "    np.random.shuffle(npd)\n",
    "    if not TEST:\n",
    "        np.random.shuffle(npd)\n",
    "    \n",
    "    # partition\n",
    "    cut1 = int(n*partition[0]/sum(partition))\n",
    "    cut2 = int((n*(partition[0] + partition[1])/sum(partition)))\n",
    "    # print(cut1, cut2)\n",
    "    train_set = npd[:cut1, :]\n",
    "    valid_set = npd[cut1:cut2, :]\n",
    "    test_set = npd[cut2:, :]\n",
    "    \n",
    "    return train_set, valid_set, test_set, tag_to_id, id_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = load_data(fname)\n",
    "# print(len(dat))\n",
    "traind, validd, testd, tag2id, id2tag = dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9, 3.1, 4.9, 1.5, 1],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1],\n",
       "       [6.5, 3.0, 5.8, 2.2, 2],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0],\n",
       "       [4.8, 3.0, 1.4, 0.3, 0],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0],\n",
       "       [4.9, 2.4, 3.3, 1.0, 1],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2]], dtype=object)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(data, feature_id = -1, threshold = None):\n",
    "    n = len(data)\n",
    "    sigma = 0.0\n",
    "    # first dimension, lc or rc\n",
    "    # second dimension, map label type to cnt, map[n_class] = total\n",
    "    group_labels = [defaultdict(int), defaultdict(int)] # group 1 stat, group 2 stat\n",
    "    for d in data:\n",
    "        if feature_id == -1:\n",
    "            group_labels[0][d[LAB]] += 1\n",
    "            group_labels[0][n_class] += 1\n",
    "        else:\n",
    "            group_labels[d[feature_id] < threshold][d[LAB]] += 1\n",
    "            group_labels[d[feature_id] < threshold][n_class] += 1 #total\n",
    "    #print(group_labels)\n",
    "    for g in group_labels:\n",
    "        w = g[n_class]/n\n",
    "        cur = 0.0\n",
    "        if(g[n_class] == 0):\n",
    "            continue\n",
    "        for i in range(n_class):\n",
    "            p = g[i]/g[n_class]\n",
    "            cur += p*p\n",
    "        sigma += w*cur\n",
    "    return 1 - sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gini(testd) # d, 0, 0 should be ~2/3 by direct calc\n",
    "Gini(testd, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(): # subtree\n",
    "    def __init__(self):\n",
    "        self.c = [None, None] # child, c[0] => < threshold , c[1]\n",
    "        self.sf = None # split feature\n",
    "        self.th = None # threshould\n",
    "        self.maj = None # majority label in this subtree\n",
    "        self.depth = None #depth\n",
    "        self.leaf = True\n",
    "    \n",
    "    def split(self, data, criterion=\"gini\", max_features=None, max_depth=None, min_impurity_decrease=None, depth=0): \n",
    "        n = len(data)\n",
    "        self.depth = depth\n",
    "        if min_impurity_decrease == None:\n",
    "            min_impurity_decrease = 0.000001 # inf small to represent any gain > epsilon is ok\n",
    "        \n",
    "        # criterion => func\n",
    "        if criterion == \"gini\":\n",
    "            func = Gini\n",
    "        elif criterion == \"entropy\":\n",
    "            func = None\n",
    "        else:\n",
    "            print(\"not a valid critirien, using Gini's impuraty\")\n",
    "            func = Gini\n",
    "        \n",
    "        # calc majority\n",
    "        vote = defaultdict(int)\n",
    "        for d in data:\n",
    "            vote[d[LAB]] += 1\n",
    "        self.maj = max(vote, key=vote.get)\n",
    "        \n",
    "        # feature_mask\n",
    "        if max_features = :\n",
    "            canuse = np.ones(n_feature)\n",
    "        \n",
    "        # select feature \n",
    "        best_gain = 0.0\n",
    "        best_branch = (None, None)\n",
    "        cur_func = func(data)\n",
    "        # cut if impurity is low enough\n",
    "        if(cur_func < min_impurity_decrease):\n",
    "            self.leaf = True\n",
    "            return \n",
    "        \n",
    "        for f in range(n_feature):\n",
    "            if(not canuse[f]):\n",
    "                continue\n",
    "            #print(data.shape)\n",
    "            sort_by_f = data[data[:,f].argsort()]\n",
    "            for i in range(n-1):\n",
    "                th = (sort_by_f[i+1][f] + sort_by_f[i][f])/2\n",
    "                #print(th)\n",
    "                cur_gain = abs(func(sort_by_f, f, th) - cur_func)\n",
    "                if(cur_gain > best_gain):\n",
    "                    best_branch = (f, th)\n",
    "                    best_gain = cur_gain\n",
    "        \n",
    "        # cut if no gain \n",
    "        if(best_gain < min_impurity_decrease):\n",
    "            self.leaf = True\n",
    "            return \n",
    "        else:\n",
    "            self.leaf = False\n",
    "        \n",
    "        ## actually split by best\n",
    "        self.sf = best_branch[0]\n",
    "        self.th = best_branch[1]\n",
    "        \n",
    "        c_data = [[], []]\n",
    "        for d in data:\n",
    "            c_data[d[best_branch[0]] < best_branch[1]].append(d)\n",
    "        #print(c_data)\n",
    "        self.c = [None, None]\n",
    "        for i in range(2):\n",
    "            self.c[i] = Node()\n",
    "            self.c[i].split(np.array(c_data[i]), criterion, max_features, max_depth, min_impurity_decrease, depth+1)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self):\n",
    "        self.rt = Node()\n",
    "    def train(self, dataset):\n",
    "        self.rt.split(dataset, \"gini\")\n",
    "    def predict(self, v):\n",
    "        cur = self.rt\n",
    "        while(cur.leaf == False):\n",
    "            cur = cur.c[v[cur.sf] < cur.th]\n",
    "        return cur.maj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = CART()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree.train(traind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(dtree.predict(testd[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ac(dtree, testd):\n",
    "    total = 0.0\n",
    "    succ = 0.0\n",
    "    for d in testd:\n",
    "        succ += int( dtree.predict(d) == d[LAB])\n",
    "        total += 1\n",
    "    return succ/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ac(dtree, traind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, criterion=\"gini\", max_features=\"sqrt\", max_depth=None, min_impurity_decrease=None, bootstrap=True, max_samples=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.dtrees = []\n",
    "    def train(data):\n",
    "        for i in range(n_estimators):\n",
    "            ti = CART()\n",
    "            ti.train(bootstrap_data, )\n",
    "            self.dtrees.append(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
