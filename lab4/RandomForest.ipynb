{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Params and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./dat/iris.data\"\n",
    "TEST = True\n",
    "n_feature = 4\n",
    "n_class = 3\n",
    "LAB = 4\n",
    "epsilon = 0.00000001\n",
    "# control default func in train or split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname, partition=(8,1,1)):\n",
    "    # read in, df to nparray\n",
    "    df = pd.read_csv(fname, header=None)\n",
    "    npd = np.array(df)\n",
    "    n = npd.shape[0]\n",
    "    \n",
    "    # tag to id, id to tag, transform\n",
    "    tag_map = defaultdict(int)\n",
    "    tag_to_id = defaultdict(int)\n",
    "    id_to_tag = defaultdict(int)\n",
    "    for d in npd:\n",
    "        tag_map[d[LAB]] += 1\n",
    "    \n",
    "    cnt = 0\n",
    "    for k, v in tag_map.items():\n",
    "        id_to_tag[cnt] = k\n",
    "        tag_to_id[k] = cnt\n",
    "        cnt += 1\n",
    "        \n",
    "    for i in range(n):\n",
    "        npd[i][LAB] = tag_to_id[npd[i][LAB]]\n",
    "    #print(tag_to_id)\n",
    "    #print(id_to_tag)\n",
    "    \n",
    "    # shuffle(no when testing)\n",
    "    np.random.shuffle(npd)\n",
    "    if not TEST:\n",
    "        np.random.shuffle(npd)\n",
    "    \n",
    "    # partition\n",
    "    cut1 = int(n*partition[0]/sum(partition))\n",
    "    cut2 = int((n*(partition[0] + partition[1])/sum(partition)))\n",
    "    # print(cut1, cut2)\n",
    "    train_set = npd[:cut1, :]\n",
    "    valid_set = npd[cut1:cut2, :]\n",
    "    test_set = npd[cut2:, :]\n",
    "    \n",
    "    return train_set, valid_set, test_set, tag_to_id, id_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = load_data(fname)\n",
    "# print(len(dat))\n",
    "traind, validd, testd, tag2id, id2tag = dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9, 3.1, 4.9, 1.5, 1],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1],\n",
       "       [6.5, 3.0, 5.8, 2.2, 2],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0],\n",
       "       [4.8, 3.0, 1.4, 0.3, 0],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0],\n",
       "       [4.9, 2.4, 3.3, 1.0, 1],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2]], dtype=object)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(data, feature_id = -1, threshold = None):\n",
    "    n = len(data)\n",
    "    sigma = 0.0\n",
    "    # first dimension, lc or rc\n",
    "    # second dimension, map label type to cnt, map[n_class] = total\n",
    "    group_labels = [defaultdict(int), defaultdict(int)] # group 1 stat, group 2 stat\n",
    "    for d in data:\n",
    "        if feature_id == -1:\n",
    "            group_labels[0][d[LAB]] += 1\n",
    "            group_labels[0][n_class] += 1\n",
    "        else:\n",
    "            group_labels[d[feature_id] < threshold][d[LAB]] += 1\n",
    "            group_labels[d[feature_id] < threshold][n_class] += 1 #total\n",
    "    #print(group_labels)\n",
    "    for g in group_labels:\n",
    "        w = g[n_class]/n\n",
    "        cur = 0.0\n",
    "        if(g[n_class] == 0):\n",
    "            continue\n",
    "        for i in range(n_class):\n",
    "            p = g[i]/g[n_class]\n",
    "            cur += p*p\n",
    "        sigma += w*cur\n",
    "    return 1 - sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gini(testd) # d, 0, 0 should be ~2/3 by direct calc\n",
    "Gini(testd, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(): # subtree\n",
    "    def __init__(self):\n",
    "        self.c = [None, None] # child, c[0] => < threshold , c[1]\n",
    "        self.sf = None # split feature\n",
    "        self.th = None # threshould\n",
    "        self.maj = None # majority label in this subtree\n",
    "        self.depth = None #depth\n",
    "        self.leaf = True\n",
    "    \n",
    "    def split(self, data, criterion=\"gini\", max_features=None, max_depth=None, min_impurity_decrease=None, depth=0): \n",
    "        n = len(data)\n",
    "        self.depth = depth\n",
    "        \n",
    "        # deal with min_impurity_decrease\n",
    "        if min_impurity_decrease == None:\n",
    "            min_impurity_decrease = epsilon # inf small to represent any gain > epsilon is ok\n",
    "        \n",
    "        # criterion => func\n",
    "        if criterion == \"gini\":\n",
    "            func = Gini\n",
    "        elif criterion == \"entropy\":\n",
    "            func = None\n",
    "        else:\n",
    "            print(\"not a valid critirien, use Gini's impurity\")\n",
    "            func = Gini\n",
    "        \n",
    "        # calc majority\n",
    "        vote = defaultdict(int)\n",
    "        for d in data:\n",
    "            vote[d[LAB]] += 1\n",
    "        self.maj = max(vote, key=vote.get)\n",
    "        \n",
    "        # cut if maxd exceed\n",
    "        if(max_depth and self.depth >= max_depth):\n",
    "            print(\"maxd_cut\")\n",
    "            self.leaf = True\n",
    "            return\n",
    "        \n",
    "        # feature_mask (max_feature)\n",
    "        mask = np.zeros(n_feature)\n",
    "        if max_features == None :\n",
    "            n_sample_f = n_feature\n",
    "        elif max_features == \"sqrt\":\n",
    "            n_sample_f = int(np.ceil(np.sqrt(n_feature)))\n",
    "        elif max_features == \"log\":\n",
    "            n_sample_f = int(np.ceil(np.log2(n_feature)))\n",
    "        elif max_features == \"one\":\n",
    "            n_sample_f = 1\n",
    "        else:\n",
    "            print(\"Error: No Such Max Feature\")\n",
    "            assert(false)\n",
    "        \n",
    "        # random.choices may with repeat\n",
    "        # random.sample without\n",
    "        sampled_features = random.sample(list(range(n_feature)), k=n_sample_f)\n",
    "        for sampled_feature in sampled_features:\n",
    "            mask[sampled_feature] = 1\n",
    "            \n",
    "        # select feature \n",
    "        best_gain = 0.0\n",
    "        best_branch = (None, None)\n",
    "        cur_func = func(data)\n",
    "        # cut if impurity is low enough\n",
    "        if(cur_func < min_impurity_decrease):\n",
    "            # print(\"min_impuraity cut\"), left element\n",
    "            self.leaf = True\n",
    "            return \n",
    "        \n",
    "        for f in range(n_feature):\n",
    "            if(not mask[f]):\n",
    "                continue\n",
    "            #print(data.shape)\n",
    "            sort_by_f = data[data[:,f].argsort()]\n",
    "            for i in range(n-1):\n",
    "                th = (sort_by_f[i+1][f] + sort_by_f[i][f])/2\n",
    "                #print(th)\n",
    "                cur_gain = abs(func(sort_by_f, f, th) - cur_func)\n",
    "                if(cur_gain > best_gain):\n",
    "                    best_branch = (f, th)\n",
    "                    best_gain = cur_gain\n",
    "        \n",
    "        # cut if not enough gain\n",
    "        if(best_gain < min_impurity_decrease):\n",
    "            print(\"min_impuraity_gain cut\")\n",
    "            self.leaf = True\n",
    "            return \n",
    "        else:\n",
    "            self.leaf = False\n",
    "        \n",
    "        # actually split by best\n",
    "        self.sf = best_branch[0]\n",
    "        self.th = best_branch[1]\n",
    "        \n",
    "        c_data = [[], []]\n",
    "        for d in data:\n",
    "            c_data[d[best_branch[0]] < best_branch[1]].append(d)\n",
    "        # print(c_data)\n",
    "        self.c = [None, None]\n",
    "        for i in range(2):\n",
    "            self.c[i] = Node()\n",
    "            self.c[i].split(np.array(c_data[i]), criterion, max_features, max_depth, min_impurity_decrease, depth+1)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self):\n",
    "        self.rt = Node()\n",
    "    def train(self, dataset, criterion=\"gini\", max_features=None, max_depth=None, min_impurity_decrease=None):\n",
    "        self.rt.split(dataset, criterion, max_features, max_depth, min_impurity_decrease)\n",
    "    def predict(self, v):\n",
    "        cur = self.rt\n",
    "        while(cur.leaf == False):\n",
    "            cur = cur.c[v[cur.sf] < cur.th]\n",
    "        return cur.maj\n",
    "    def calc_ac(self, testd):\n",
    "        total = 0.0\n",
    "        succ = 0.0\n",
    "        for d in testd:\n",
    "            succ += int(self.predict(d) == d[LAB])\n",
    "            total += 1\n",
    "        return succ/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 1.0\n"
     ]
    }
   ],
   "source": [
    "dtree = CART()\n",
    "dtree.train(traind, max_features=\"sqrt\")\n",
    "print(dtree.calc_ac(testd),\n",
    "      dtree.calc_ac(traind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, criterion=\"gini\", max_features=\"sqrt\", max_depth=None, min_impurity_decrease=None, bootstrap=True, max_samples=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.max_samples = max_samples\n",
    "        self.dtrees = []\n",
    "        self.bootstrap = bootstrap\n",
    "        \n",
    "    def train(self, data):\n",
    "        n = data.shape[0]\n",
    "        if self.max_samples == None:\n",
    "            n_population = n\n",
    "        elif type(self.max_samples) == float:\n",
    "            n_population = int(n*self.max_samples)\n",
    "        elif type(self.max_samples) == int:\n",
    "            n_poluself.lation = self.max_samples\n",
    "        else:\n",
    "            print(\"MAX SAMPLE TYPE ERROR\")\n",
    "            assert(False)\n",
    "            return\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            ti = CART()\n",
    "            if self.bootstrap == True:\n",
    "                sampled_ids = np.random.choice(n, n_population, replace=True)\n",
    "            else:\n",
    "                sampled_ids = list(range(n))\n",
    "            bootstrap_data = data[sampled_ids]\n",
    "            ti.train(bootstrap_data, criterion=self.criterion, max_features=self.max_features, max_depth=self.max_depth, min_impurity_decrease=self.min_impurity_decrease)\n",
    "            self.dtrees.append(ti)\n",
    "        return\n",
    "            \n",
    "    def predict(self, v):\n",
    "        cnt = np.zeros(n_class)\n",
    "        for i in range(self.n_estimators):\n",
    "            cnt[self.dtrees[i].predict(v)] += 1\n",
    "        return np.argmax(cnt)\n",
    "    \n",
    "    def calc_ac(self, testd):\n",
    "        total = 0.0\n",
    "        succ = 0.0\n",
    "        for d in testd:\n",
    "            succ += int(self.predict(d) == d[LAB])\n",
    "            total += 1\n",
    "        return succ/total  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest(n_estimators=100, criterion=\"gini\", max_features=\"sqrt\", max_depth=None, min_impurity_decrease=None, bootstrap=True, max_samples=None)\n",
    "rf.train(traind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(testd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rf.calc_ac(testd)+rf.calc_ac(validd))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
